{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n",
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 34;\n                var nbb_unformatted_code = \"%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_formatted_code = \"%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 35;\n                var nbb_unformatted_code = \"!jupyter nbextension enable --py widgetsnbextension\";\n                var nbb_formatted_code = \"!jupyter nbextension enable --py widgetsnbextension\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cat Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 36;\n                var nbb_unformatted_code = \"import pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom IPython.display import display\\nimport seaborn as sns\\nimport os\\nimport random\\n\\nfrom catboost import CatBoostClassifier, Pool, metrics, cv\\nfrom sklearn import preprocessing\\nfrom sklearn.metrics import roc_auc_score\\nfrom sklearn.metrics import accuracy_score\\n\\nimport eli5\\nfrom eli5.sklearn import PermutationImportance\\n\\nimport warnings\\n\\nwarnings.filterwarnings(action=\\\"ignore\\\")  # \\uacbd\\uace0 \\ucd9c\\ub825 \\ubb34\\uc2dc\";\n                var nbb_formatted_code = \"import pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom IPython.display import display\\nimport seaborn as sns\\nimport os\\nimport random\\n\\nfrom catboost import CatBoostClassifier, Pool, metrics, cv\\nfrom sklearn import preprocessing\\nfrom sklearn.metrics import roc_auc_score\\nfrom sklearn.metrics import accuracy_score\\n\\nimport eli5\\nfrom eli5.sklearn import PermutationImportance\\n\\nimport warnings\\n\\nwarnings.filterwarnings(action=\\\"ignore\\\")  # \\uacbd\\uace0 \\ucd9c\\ub825 \\ubb34\\uc2dc\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool, metrics, cv\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")  # 경고 출력 무시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 37;\n                var nbb_unformatted_code = \"data_dir = \\\"/opt/ml/input/data/\\\"  # \\uacbd\\ub85c\\ub294 \\uc0c1\\ud669\\uc5d0 \\ub9de\\ucdb0\\uc11c \\uc218\\uc815\\ud574\\uc8fc\\uc138\\uc694!\\ncsv_file_path = os.path.join(data_dir, \\\"all_feature_data.csv\\\")  # \\ub370\\uc774\\ud130\\ub294 \\ub300\\ud68c\\ud648\\ud398\\uc774\\uc9c0\\uc5d0\\uc11c \\ubc1b\\uc544\\uc8fc\\uc138\\uc694 :)\\ndf = pd.read_csv(csv_file_path)\\n\\n# \\uc720\\uc800\\ubcc4 \\uc2dc\\ud000\\uc2a4\\ub97c \\uace0\\ub824\\ud558\\uae30 \\uc704\\ud574 \\uc544\\ub798\\uc640 \\uac19\\uc774 \\uc815\\ub82c\\ndf.sort_values(by=[\\\"userID\\\", \\\"Timestamp\\\"], inplace=True)\";\n                var nbb_formatted_code = \"data_dir = \\\"/opt/ml/input/data/\\\"  # \\uacbd\\ub85c\\ub294 \\uc0c1\\ud669\\uc5d0 \\ub9de\\ucdb0\\uc11c \\uc218\\uc815\\ud574\\uc8fc\\uc138\\uc694!\\ncsv_file_path = os.path.join(data_dir, \\\"all_feature_data.csv\\\")  # \\ub370\\uc774\\ud130\\ub294 \\ub300\\ud68c\\ud648\\ud398\\uc774\\uc9c0\\uc5d0\\uc11c \\ubc1b\\uc544\\uc8fc\\uc138\\uc694 :)\\ndf = pd.read_csv(csv_file_path)\\n\\n# \\uc720\\uc800\\ubcc4 \\uc2dc\\ud000\\uc2a4\\ub97c \\uace0\\ub824\\ud558\\uae30 \\uc704\\ud574 \\uc544\\ub798\\uc640 \\uac19\\uc774 \\uc815\\ub82c\\ndf.sort_values(by=[\\\"userID\\\", \\\"Timestamp\\\"], inplace=True)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dir = \"/opt/ml/input/data/\"  # 경로는 상황에 맞춰서 수정해주세요!\n",
    "csv_file_path = os.path.join(data_dir, \"all_feature_data.csv\")  # 데이터는 대회홈페이지에서 받아주세요 :)\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# 유저별 시퀀스를 고려하기 위해 아래와 같이 정렬\n",
    "df.sort_values(by=[\"userID\", \"Timestamp\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train/Test 데이터 셋 분리 (option1, option2에서 하나만 실행)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1\n",
    "- train 데이터에서 train, valid set을 나눔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 5;\n                var nbb_unformatted_code = \"# train\\uacfc test \\ub370\\uc774\\ud130\\uc14b\\uc740 \\uc0ac\\uc6a9\\uc790 \\ubcc4\\ub85c \\ubb36\\uc5b4\\uc11c \\ubd84\\ub9ac\\ub97c \\ud574\\uc8fc\\uc5b4\\uc57c\\ud568\\nrandom.seed(42)\\n\\n\\ndef option1_train_test_split(df, ratio=0.8, split=True):\\n\\n    users = list(zip(df[\\\"userID\\\"].value_counts().index, df[\\\"userID\\\"].value_counts()))\\n    random.shuffle(users)\\n\\n    max_train_data_len = ratio * len(df)\\n    sum_of_train_data = 0\\n    user_ids = []\\n\\n    for user_id, count in users:\\n        sum_of_train_data += count\\n        if max_train_data_len < sum_of_train_data:\\n            break\\n        user_ids.append(user_id)\\n\\n    train = df[df[\\\"userID\\\"].isin(user_ids)]\\n    test = df[df[\\\"userID\\\"].isin(user_ids) == False]\\n\\n    # test\\ub370\\uc774\\ud130\\uc14b\\uc740 \\uac01 \\uc720\\uc800\\uc758 \\ub9c8\\uc9c0\\ub9c9 interaction\\ub9cc \\ucd94\\ucd9c\\n    test = test[test[\\\"userID\\\"] != test[\\\"userID\\\"].shift(-1)]\\n    return train, test\";\n                var nbb_formatted_code = \"# train\\uacfc test \\ub370\\uc774\\ud130\\uc14b\\uc740 \\uc0ac\\uc6a9\\uc790 \\ubcc4\\ub85c \\ubb36\\uc5b4\\uc11c \\ubd84\\ub9ac\\ub97c \\ud574\\uc8fc\\uc5b4\\uc57c\\ud568\\nrandom.seed(42)\\n\\n\\ndef option1_train_test_split(df, ratio=0.8, split=True):\\n\\n    users = list(zip(df[\\\"userID\\\"].value_counts().index, df[\\\"userID\\\"].value_counts()))\\n    random.shuffle(users)\\n\\n    max_train_data_len = ratio * len(df)\\n    sum_of_train_data = 0\\n    user_ids = []\\n\\n    for user_id, count in users:\\n        sum_of_train_data += count\\n        if max_train_data_len < sum_of_train_data:\\n            break\\n        user_ids.append(user_id)\\n\\n    train = df[df[\\\"userID\\\"].isin(user_ids)]\\n    test = df[df[\\\"userID\\\"].isin(user_ids) == False]\\n\\n    # test\\ub370\\uc774\\ud130\\uc14b\\uc740 \\uac01 \\uc720\\uc800\\uc758 \\ub9c8\\uc9c0\\ub9c9 interaction\\ub9cc \\ucd94\\ucd9c\\n    test = test[test[\\\"userID\\\"] != test[\\\"userID\\\"].shift(-1)]\\n    return train, test\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train과 test 데이터셋은 사용자 별로 묶어서 분리를 해주어야함\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "def option1_train_test_split(df, ratio=0.8, split=True):\n",
    "\n",
    "    users = list(zip(df[\"userID\"].value_counts().index, df[\"userID\"].value_counts()))\n",
    "    random.shuffle(users)\n",
    "\n",
    "    max_train_data_len = ratio * len(df)\n",
    "    sum_of_train_data = 0\n",
    "    user_ids = []\n",
    "\n",
    "    for user_id, count in users:\n",
    "        sum_of_train_data += count\n",
    "        if max_train_data_len < sum_of_train_data:\n",
    "            break\n",
    "        user_ids.append(user_id)\n",
    "\n",
    "    train = df[df[\"userID\"].isin(user_ids)]\n",
    "    test = df[df[\"userID\"].isin(user_ids) == False]\n",
    "\n",
    "    # test데이터셋은 각 유저의 마지막 interaction만 추출\n",
    "    test = test[test[\"userID\"] != test[\"userID\"].shift(-1)]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2\n",
    "- train 데이터를 모두 훈련에 사용\n",
    "- valid를 test셋의 마지막 두번째 데이터로 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 38;\n                var nbb_unformatted_code = \"def option2_train_test_split(df):\\n    # use train dataset only for train\\n    train = df[df.dataset == 1]\\n\\n    # use test dataset only for valid\\n    test = df[(df.dataset == 2) & (df.answerCode != -1)]  # -1 \\uc778 answerCode \\uc81c\\uc678\\n\\n    # test\\ub370\\uc774\\ud130\\uc14b\\uc740 \\uac01 \\uc720\\uc800\\uc758 \\ub9c8\\uc9c0\\ub9c9 interaction\\ub9cc \\ucd94\\ucd9c\\n    test = test[test[\\\"userID\\\"] != test[\\\"userID\\\"].shift(-1)]\\n\\n    return train, test\";\n                var nbb_formatted_code = \"def option2_train_test_split(df):\\n    # use train dataset only for train\\n    train = df[df.dataset == 1]\\n\\n    # use test dataset only for valid\\n    test = df[(df.dataset == 2) & (df.answerCode != -1)]  # -1 \\uc778 answerCode \\uc81c\\uc678\\n\\n    # test\\ub370\\uc774\\ud130\\uc14b\\uc740 \\uac01 \\uc720\\uc800\\uc758 \\ub9c8\\uc9c0\\ub9c9 interaction\\ub9cc \\ucd94\\ucd9c\\n    test = test[test[\\\"userID\\\"] != test[\\\"userID\\\"].shift(-1)]\\n\\n    return train, test\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def option2_train_test_split(df):\n",
    "    # use train dataset only for train\n",
    "    train = df[df.dataset == 1]\n",
    "\n",
    "    # use test dataset only for valid\n",
    "    test = df[(df.dataset == 2) & (df.answerCode != -1)]  # -1 인 answerCode 제외\n",
    "\n",
    "    # test데이터셋은 각 유저의 마지막 interaction만 추출\n",
    "    test = test[test[\"userID\"] != test[\"userID\"].shift(-1)]\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 39;\n                var nbb_unformatted_code = \"def feature_engineering(df, option=\\\"option1\\\"):\\n\\n    # \\uce74\\ud14c\\uace0\\ub9ac\\ud615 feature\\n    categories = [\\n        \\\"assessmentItemID\\\",\\n        \\\"testId\\\",\\n        \\\"KnowledgeTag\\\",\\n        \\\"bigClassAccCate\\\",\\n        \\\"bigClass\\\",\\n        \\\"KTAccuracyCate\\\",\\n        \\\"day\\\",\\n        \\\"month\\\",\\n        \\\"year\\\",\\n        \\\"wday\\\",\\n        \\\"weekNum\\\",\\n        \\\"hour\\\",\\n        \\\"elapsedTimeClass\\\",\\n        \\\"tagCluster\\\",\\n        \\\"testLV\\\",\\n        \\\"userLVbyTest\\\",\\n        \\\"userLVbyTestAVG\\\",\\n        \\\"tagLV\\\",\\n        \\\"userLVbyTag\\\",\\n        \\\"userLVbyTagAVG\\\",\\n    ]  # TODO : category feature\\ub97c \\ubcc0\\ud658\\uc2dc\\ucf1c\\uc918\\uc57c\\ud568\\n\\n    le = preprocessing.LabelEncoder()\\n    # df[\\\"elo\\\"] = df[\\\"elo\\\"].transform(lambda x: int(x * 100000000))\\n\\n    if option == \\\"total\\\":\\n        for category in categories:\\n            if df[category].dtypes != \\\"int\\\":\\n                df[category] = le.fit_transform(df[category])\\n            df[category] = df[category].astype(\\\"category\\\")\\n\\n        return df\\n\\n    if option == \\\"option1\\\":\\n        # \\uc720\\uc800 \\ubcc4 \\ubd84\\ub9ac\\n        train_df = df[(df.dataset == 1)]\\n        train, valid = option1_train_test_split(train_df)\\n    elif option == \\\"option2\\\":\\n        train, valid = option2_train_test_split(df)\\n\\n    for category in categories:\\n        if train[category].dtypes != \\\"int\\\":  # float, str type -> int\\ub85c \\uc804\\ud658\\n            train[category] = le.fit_transform(train[category])\\n            valid[category] = le.transform(valid[category])\\n\\n        train[category] = train[category].astype(\\\"category\\\")\\n        valid[category] = valid[category].astype(\\\"category\\\")\\n\\n    return train, valid\";\n                var nbb_formatted_code = \"def feature_engineering(df, option=\\\"option1\\\"):\\n\\n    # \\uce74\\ud14c\\uace0\\ub9ac\\ud615 feature\\n    categories = [\\n        \\\"assessmentItemID\\\",\\n        \\\"testId\\\",\\n        \\\"KnowledgeTag\\\",\\n        \\\"bigClassAccCate\\\",\\n        \\\"bigClass\\\",\\n        \\\"KTAccuracyCate\\\",\\n        \\\"day\\\",\\n        \\\"month\\\",\\n        \\\"year\\\",\\n        \\\"wday\\\",\\n        \\\"weekNum\\\",\\n        \\\"hour\\\",\\n        \\\"elapsedTimeClass\\\",\\n        \\\"tagCluster\\\",\\n        \\\"testLV\\\",\\n        \\\"userLVbyTest\\\",\\n        \\\"userLVbyTestAVG\\\",\\n        \\\"tagLV\\\",\\n        \\\"userLVbyTag\\\",\\n        \\\"userLVbyTagAVG\\\",\\n    ]  # TODO : category feature\\ub97c \\ubcc0\\ud658\\uc2dc\\ucf1c\\uc918\\uc57c\\ud568\\n\\n    le = preprocessing.LabelEncoder()\\n    # df[\\\"elo\\\"] = df[\\\"elo\\\"].transform(lambda x: int(x * 100000000))\\n\\n    if option == \\\"total\\\":\\n        for category in categories:\\n            if df[category].dtypes != \\\"int\\\":\\n                df[category] = le.fit_transform(df[category])\\n            df[category] = df[category].astype(\\\"category\\\")\\n\\n        return df\\n\\n    if option == \\\"option1\\\":\\n        # \\uc720\\uc800 \\ubcc4 \\ubd84\\ub9ac\\n        train_df = df[(df.dataset == 1)]\\n        train, valid = option1_train_test_split(train_df)\\n    elif option == \\\"option2\\\":\\n        train, valid = option2_train_test_split(df)\\n\\n    for category in categories:\\n        if train[category].dtypes != \\\"int\\\":  # float, str type -> int\\ub85c \\uc804\\ud658\\n            train[category] = le.fit_transform(train[category])\\n            valid[category] = le.transform(valid[category])\\n\\n        train[category] = train[category].astype(\\\"category\\\")\\n        valid[category] = valid[category].astype(\\\"category\\\")\\n\\n    return train, valid\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def feature_engineering(df, option=\"option1\"):\n",
    "\n",
    "    # 카테고리형 feature\n",
    "    categories = [\n",
    "        \"assessmentItemID\",\n",
    "        \"testId\",\n",
    "        \"KnowledgeTag\",\n",
    "        \"bigClassAccCate\",\n",
    "        \"bigClass\",\n",
    "        \"KTAccuracyCate\",\n",
    "        \"day\",\n",
    "        \"month\",\n",
    "        \"year\",\n",
    "        \"wday\",\n",
    "        \"weekNum\",\n",
    "        \"hour\",\n",
    "        \"elapsedTimeClass\",\n",
    "        \"tagCluster\",\n",
    "        \"testLV\",\n",
    "        \"userLVbyTest\",\n",
    "        \"userLVbyTestAVG\",\n",
    "        \"tagLV\",\n",
    "        \"userLVbyTag\",\n",
    "        \"userLVbyTagAVG\",\n",
    "    ]  # TODO : category feature를 변환시켜줘야함\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    # df[\"elo\"] = df[\"elo\"].transform(lambda x: int(x * 100000000))\n",
    "\n",
    "    if option == \"total\":\n",
    "        for category in categories:\n",
    "            if df[category].dtypes != \"int\":\n",
    "                df[category] = le.fit_transform(df[category])\n",
    "            df[category] = df[category].astype(\"category\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    if option == \"option1\":\n",
    "        # 유저 별 분리\n",
    "        train_df = df[(df.dataset == 1)]\n",
    "        train, valid = option1_train_test_split(train_df)\n",
    "    elif option == \"option2\":\n",
    "        train, valid = option2_train_test_split(df)\n",
    "\n",
    "    for category in categories:\n",
    "        if train[category].dtypes != \"int\":  # float, str type -> int로 전환\n",
    "            train[category] = le.fit_transform(train[category])\n",
    "            valid[category] = le.transform(valid[category])\n",
    "\n",
    "        train[category] = train[category].astype(\"category\")\n",
    "        valid[category] = valid[category].astype(\"category\")\n",
    "\n",
    "    return train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>assessmentItemID</th>\n",
       "      <th>testId</th>\n",
       "      <th>answerCode</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>KnowledgeTag</th>\n",
       "      <th>dataset</th>\n",
       "      <th>tagLV</th>\n",
       "      <th>cumCorrect</th>\n",
       "      <th>elo</th>\n",
       "      <th>...</th>\n",
       "      <th>testLV</th>\n",
       "      <th>seenCount</th>\n",
       "      <th>userLVbyTag</th>\n",
       "      <th>userLVbyTagAVG</th>\n",
       "      <th>tagCount</th>\n",
       "      <th>weekNum</th>\n",
       "      <th>bigClassCount</th>\n",
       "      <th>wday</th>\n",
       "      <th>recCount</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5354</td>\n",
       "      <td>975</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:11</td>\n",
       "      <td>7224</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.980768</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>274</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5355</td>\n",
       "      <td>975</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:14</td>\n",
       "      <td>7225</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973315</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>274</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5356</td>\n",
       "      <td>975</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:22</td>\n",
       "      <td>7225</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.947292</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>274</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5357</td>\n",
       "      <td>975</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:29</td>\n",
       "      <td>7225</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.974914</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>274</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5358</td>\n",
       "      <td>975</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:36</td>\n",
       "      <td>7225</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.961391</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>274</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID assessmentItemID testId  answerCode            Timestamp  \\\n",
       "0       0             5354    975           1  2020-03-24 00:17:11   \n",
       "1       0             5355    975           1  2020-03-24 00:17:14   \n",
       "2       0             5356    975           1  2020-03-24 00:17:22   \n",
       "3       0             5357    975           1  2020-03-24 00:17:29   \n",
       "4       0             5358    975           1  2020-03-24 00:17:36   \n",
       "\n",
       "  KnowledgeTag  dataset tagLV  cumCorrect       elo  ... testLV seenCount  \\\n",
       "0         7224        1     0         0.0  0.980768  ...      0         0   \n",
       "1         7225        1     0         1.0  0.973315  ...      0         0   \n",
       "2         7225        1     0         2.0  0.947292  ...      0         0   \n",
       "3         7225        1     0         3.0  0.974914  ...      0         0   \n",
       "4         7225        1     0         4.0  0.961391  ...      0         0   \n",
       "\n",
       "  userLVbyTag userLVbyTagAVG tagCount weekNum  bigClassCount  wday recCount  \\\n",
       "0          10             34        0      13            274     1        1   \n",
       "1          10             34        0      13            274     1        2   \n",
       "2          10             34        1      13            274     1        3   \n",
       "3          10             34        2      13            274     1        4   \n",
       "4          10             34        3      13            274     1        5   \n",
       "\n",
       "   year  \n",
       "0  2020  \n",
       "1  2020  \n",
       "2  2020  \n",
       "3  2020  \n",
       "4  2020  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 40;\n                var nbb_unformatted_code = \"train, valid = feature_engineering(df, option=\\\"option1\\\")\\ntrain.head()\";\n                var nbb_formatted_code = \"train, valid = feature_engineering(df, option=\\\"option1\\\")\\ntrain.head()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, valid = feature_engineering(df, option=\"option1\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터셋 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 41;\n                var nbb_unformatted_code = \"# X, y \\uac12 \\ubd84\\ub9ac\\ny_train = train[\\\"answerCode\\\"]\\ntrain = train.drop([\\\"answerCode\\\"], axis=1)\\n\\ny_valid = valid[\\\"answerCode\\\"]\\nvalid = valid.drop([\\\"answerCode\\\"], axis=1)\";\n                var nbb_formatted_code = \"# X, y \\uac12 \\ubd84\\ub9ac\\ny_train = train[\\\"answerCode\\\"]\\ntrain = train.drop([\\\"answerCode\\\"], axis=1)\\n\\ny_valid = valid[\\\"answerCode\\\"]\\nvalid = valid.drop([\\\"answerCode\\\"], axis=1)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# X, y 값 분리\n",
    "y_train = train[\"answerCode\"]\n",
    "train = train.drop([\"answerCode\"], axis=1)\n",
    "\n",
    "y_valid = valid[\"answerCode\"]\n",
    "valid = valid.drop([\"answerCode\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 42;\n                var nbb_unformatted_code = \"# TODO :\\uc0ac\\uc6a9\\ud560 Feature \\uc124\\uc815\\nFEATS = [\\n    #\\\"assessmentItemID\\\",\\n    \\\"testId\\\",\\n    \\\"KnowledgeTag\\\",\\n    # \\\"user_acc\\\",\\n    # \\\"user_total_answer\\\",\\n    # \\\"test_mean\\\",\\n    # \\\"test_sum\\\",\\n    # \\\"tag_mean\\\",\\n    # \\\"tag_sum\\\",\\n    # -- \\uc5ec\\uae30\\uc11c\\ubd80\\ud130 Custom Feature Engineering\\n    \\\"bigClass\\\",\\n    # \\\"bigClassAcc\\\",\\n    # \\\"bigClassAccCate\\\",\\n    # \\\"recAccuracy\\\",\\n    # \\\"cumAccuracy\\\",\\n    # \\\"cumCorrect\\\",\\n    \\\"day\\\",\\n    \\\"month\\\",\\n    \\\"year\\\",\\n    \\\"wday\\\",\\n    \\\"weekNum\\\",\\n    \\\"hour\\\",\\n    \\\"elapsedTime\\\",\\n    \\\"elapsedTimeClass\\\",\\n    # \\\"KnowledgeTagAcc\\\",\\n    # \\\"KTAccuracyCate\\\",\\n    \\\"seenCount\\\",\\n    \\\"tagCluster\\\",\\n    \\\"tagCount\\\",\\n    # \\\"testLV\\\",\\n    # \\\"userLVbyTest\\\",\\n    \\\"userLVbyTestAVG\\\",\\n    # \\\"tagLV\\\",\\n    # \\\"userLVbyTag\\\",\\n    \\\"userLVbyTagAVG\\\",\\n    # \\\"bigClassCount\\\",\\n    \\\"bigClassElaspedTimeAvg\\\",\\n    # \\\"recCount\\\",\\n    \\\"elo\\\",\\n]\";\n                var nbb_formatted_code = \"# TODO :\\uc0ac\\uc6a9\\ud560 Feature \\uc124\\uc815\\nFEATS = [\\n    # \\\"assessmentItemID\\\",\\n    \\\"testId\\\",\\n    \\\"KnowledgeTag\\\",\\n    # \\\"user_acc\\\",\\n    # \\\"user_total_answer\\\",\\n    # \\\"test_mean\\\",\\n    # \\\"test_sum\\\",\\n    # \\\"tag_mean\\\",\\n    # \\\"tag_sum\\\",\\n    # -- \\uc5ec\\uae30\\uc11c\\ubd80\\ud130 Custom Feature Engineering\\n    \\\"bigClass\\\",\\n    # \\\"bigClassAcc\\\",\\n    # \\\"bigClassAccCate\\\",\\n    # \\\"recAccuracy\\\",\\n    # \\\"cumAccuracy\\\",\\n    # \\\"cumCorrect\\\",\\n    \\\"day\\\",\\n    \\\"month\\\",\\n    \\\"year\\\",\\n    \\\"wday\\\",\\n    \\\"weekNum\\\",\\n    \\\"hour\\\",\\n    \\\"elapsedTime\\\",\\n    \\\"elapsedTimeClass\\\",\\n    # \\\"KnowledgeTagAcc\\\",\\n    # \\\"KTAccuracyCate\\\",\\n    \\\"seenCount\\\",\\n    \\\"tagCluster\\\",\\n    \\\"tagCount\\\",\\n    # \\\"testLV\\\",\\n    # \\\"userLVbyTest\\\",\\n    \\\"userLVbyTestAVG\\\",\\n    # \\\"tagLV\\\",\\n    # \\\"userLVbyTag\\\",\\n    \\\"userLVbyTagAVG\\\",\\n    # \\\"bigClassCount\\\",\\n    \\\"bigClassElaspedTimeAvg\\\",\\n    # \\\"recCount\\\",\\n    \\\"elo\\\",\\n]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO :사용할 Feature 설정\n",
    "FEATS = [\n",
    "    # \"assessmentItemID\",\n",
    "    \"testId\",\n",
    "    \"KnowledgeTag\",\n",
    "    # \"user_acc\",\n",
    "    # \"user_total_answer\",\n",
    "    # \"test_mean\",\n",
    "    # \"test_sum\",\n",
    "    # \"tag_mean\",\n",
    "    # \"tag_sum\",\n",
    "    # -- 여기서부터 Custom Feature Engineering\n",
    "    \"bigClass\",\n",
    "    # \"bigClassAcc\",\n",
    "    # \"bigClassAccCate\",\n",
    "    # \"recAccuracy\",\n",
    "    # \"cumAccuracy\",\n",
    "    # \"cumCorrect\",\n",
    "    \"day\",\n",
    "    \"month\",\n",
    "    \"year\",\n",
    "    \"wday\",\n",
    "    \"weekNum\",\n",
    "    \"hour\",\n",
    "    \"elapsedTime\",\n",
    "    \"elapsedTimeClass\",\n",
    "    # \"KnowledgeTagAcc\",\n",
    "    # \"KTAccuracyCate\",\n",
    "    \"seenCount\",\n",
    "    \"tagCluster\",\n",
    "    \"tagCount\",\n",
    "    # \"testLV\",\n",
    "    # \"userLVbyTest\",\n",
    "    \"userLVbyTestAVG\",\n",
    "    # \"tagLV\",\n",
    "    # \"userLVbyTag\",\n",
    "    \"userLVbyTagAVG\",\n",
    "    # \"bigClassCount\",\n",
    "    \"bigClassElaspedTimeAvg\",\n",
    "    # \"recCount\",\n",
    "    \"elo\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "testId                    category\n",
       "KnowledgeTag              category\n",
       "bigClass                  category\n",
       "day                       category\n",
       "month                     category\n",
       "year                      category\n",
       "wday                      category\n",
       "weekNum                   category\n",
       "hour                      category\n",
       "elapsedTime                  int64\n",
       "elapsedTimeClass          category\n",
       "seenCount                    int64\n",
       "tagCluster                category\n",
       "tagCount                     int64\n",
       "userLVbyTestAVG           category\n",
       "userLVbyTagAVG            category\n",
       "bigClassElaspedTimeAvg       int64\n",
       "elo                        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 43;\n                var nbb_unformatted_code = \"train[FEATS].dtypes\";\n                var nbb_formatted_code = \"train[FEATS].dtypes\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[FEATS].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_cols: ['testId', 'KnowledgeTag', 'bigClass', 'day', 'month', 'year', 'wday', 'weekNum', 'hour', 'elapsedTimeClass', 'tagCluster', 'userLVbyTestAVG', 'userLVbyTagAVG']\n",
      "num_cols: ['elapsedTime', 'seenCount', 'tagCount', 'bigClassElaspedTimeAvg', 'elo']\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 44;\n                var nbb_unformatted_code = \"cat_cols = train[FEATS].columns[train[FEATS].dtypes == \\\"category\\\"].to_list()\\nnum_cols = train[FEATS].columns[train[FEATS].dtypes != \\\"category\\\"].to_list()\\n\\nprint(f\\\"cat_cols: {cat_cols}\\\")\\nprint(f\\\"num_cols: {num_cols}\\\")\";\n                var nbb_formatted_code = \"cat_cols = train[FEATS].columns[train[FEATS].dtypes == \\\"category\\\"].to_list()\\nnum_cols = train[FEATS].columns[train[FEATS].dtypes != \\\"category\\\"].to_list()\\n\\nprint(f\\\"cat_cols: {cat_cols}\\\")\\nprint(f\\\"num_cols: {num_cols}\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_cols = train[FEATS].columns[train[FEATS].dtypes == \"category\"].to_list()\n",
    "num_cols = train[FEATS].columns[train[FEATS].dtypes != \"category\"].to_list()\n",
    "\n",
    "print(f\"cat_cols: {cat_cols}\")\n",
    "print(f\"num_cols: {num_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 훈련 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 13;\n                var nbb_unformatted_code = \"train_pool = Pool(train[FEATS], y_train, cat_features=cat_cols)\\neval_pool = Pool(valid[FEATS], y_valid, cat_features=cat_cols)\";\n                var nbb_formatted_code = \"train_pool = Pool(train[FEATS], y_train, cat_features=cat_cols)\\neval_pool = Pool(valid[FEATS], y_valid, cat_features=cat_cols)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_pool = Pool(train[FEATS], y_train, cat_features=cat_cols)\n",
    "eval_pool = Pool(valid[FEATS], y_valid, cat_features=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeaaf06363b341f1b8405aebbf36e39d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/workspace/CatBoost/CatBoost.ipynb Cell 22'\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B101.101.208.64/opt/ml/workspace/CatBoost/CatBoost.ipynb#ch0000024vscode-remote?line=0'>1</a>\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B101.101.208.64/opt/ml/workspace/CatBoost/CatBoost.ipynb#ch0000024vscode-remote?line=1'>2</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39miterations\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1000\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B101.101.208.64/opt/ml/workspace/CatBoost/CatBoost.ipynb#ch0000024vscode-remote?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0.06\u001b[39m,  \u001b[39m# 0.1\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.208.64/opt/ml/workspace/CatBoost/CatBoost.ipynb#ch0000024vscode-remote?line=10'>11</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcat_features\u001b[39m\u001b[39m\"\u001b[39m: cat_cols,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.208.64/opt/ml/workspace/CatBoost/CatBoost.ipynb#ch0000024vscode-remote?line=11'>12</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.208.64/opt/ml/workspace/CatBoost/CatBoost.ipynb#ch0000024vscode-remote?line=13'>14</a>\u001b[0m model \u001b[39m=\u001b[39m CatBoostClassifier(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.208.64/opt/ml/workspace/CatBoost/CatBoost.ipynb#ch0000024vscode-remote?line=14'>15</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.208.64/opt/ml/workspace/CatBoost/CatBoost.ipynb#ch0000024vscode-remote?line=15'>16</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B101.101.208.64/opt/ml/workspace/CatBoost/CatBoost.ipynb#ch0000024vscode-remote?line=17'>18</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.208.64/opt/ml/workspace/CatBoost/CatBoost.ipynb#ch0000024vscode-remote?line=18'>19</a>\u001b[0m     train[FEATS],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.208.64/opt/ml/workspace/CatBoost/CatBoost.ipynb#ch0000024vscode-remote?line=19'>20</a>\u001b[0m     y_train,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.208.64/opt/ml/workspace/CatBoost/CatBoost.ipynb#ch0000024vscode-remote?line=20'>21</a>\u001b[0m     eval_set\u001b[39m=\u001b[39;49m[(train[FEATS], y_train), (valid[FEATS], y_valid)],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.208.64/opt/ml/workspace/CatBoost/CatBoost.ipynb#ch0000024vscode-remote?line=21'>22</a>\u001b[0m     \u001b[39m# cat_features=cat_cols,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.208.64/opt/ml/workspace/CatBoost/CatBoost.ipynb#ch0000024vscode-remote?line=22'>23</a>\u001b[0m     plot\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.208.64/opt/ml/workspace/CatBoost/CatBoost.ipynb#ch0000024vscode-remote?line=23'>24</a>\u001b[0m     \u001b[39m# logging_level=\"Verbose\",  # you can uncomment this for text output\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.208.64/opt/ml/workspace/CatBoost/CatBoost.ipynb#ch0000024vscode-remote?line=24'>25</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.208.64/opt/ml/workspace/CatBoost/CatBoost.ipynb#ch0000024vscode-remote?line=26'>27</a>\u001b[0m preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict_proba(valid[FEATS])[:, \u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.208.64/opt/ml/workspace/CatBoost/CatBoost.ipynb#ch0000024vscode-remote?line=27'>28</a>\u001b[0m acc \u001b[39m=\u001b[39m accuracy_score(y_valid, np\u001b[39m.\u001b[39mwhere(preds \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/catboost/core.py:4921\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/catboost/core.py?line=4917'>4918</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/catboost/core.py?line=4918'>4919</a>\u001b[0m     CatBoostClassifier\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m-> <a href='file:///opt/conda/lib/python3.8/site-packages/catboost/core.py?line=4920'>4921</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline, use_best_model,\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/catboost/core.py?line=4921'>4922</a>\u001b[0m           eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period,\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/catboost/core.py?line=4922'>4923</a>\u001b[0m           silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/catboost/core.py?line=4923'>4924</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/catboost/core.py:2192\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/catboost/core.py?line=2187'>2188</a>\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/catboost/core.py?line=2189'>2190</a>\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/catboost/core.py?line=2190'>2191</a>\u001b[0m     plot_wrapper(plot, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[0;32m-> <a href='file:///opt/conda/lib/python3.8/site-packages/catboost/core.py?line=2191'>2192</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/catboost/core.py?line=2192'>2193</a>\u001b[0m         train_pool,\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/catboost/core.py?line=2193'>2194</a>\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/catboost/core.py?line=2194'>2195</a>\u001b[0m         params,\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/catboost/core.py?line=2195'>2196</a>\u001b[0m         allow_clear_pool,\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/catboost/core.py?line=2196'>2197</a>\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/catboost/core.py?line=2197'>2198</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/catboost/core.py?line=2199'>2200</a>\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/catboost/core.py?line=2200'>2201</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/catboost/core.py:1619\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/catboost/core.py?line=1617'>1618</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> <a href='file:///opt/conda/lib/python3.8/site-packages/catboost/core.py?line=1618'>1619</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/catboost/core.py?line=1619'>1620</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4408\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4457\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 51;\n                var nbb_unformatted_code = \"params = {\\n    \\\"iterations\\\": 1000,\\n    \\\"learning_rate\\\": 0.06,  # 0.1\\n    \\\"eval_metric\\\": \\\"AUC\\\",\\n    \\\"random_seed\\\": 42,\\n    \\\"logging_level\\\": \\\"Silent\\\",\\n    \\\"early_stopping_rounds\\\": 50,\\n    \\\"use_best_model\\\": True,\\n    #\\\"task_type\\\": \\\"GPU\\\",\\n    \\\"bagging_temperature\\\": 1,\\n    \\\"cat_features\\\": cat_cols,\\n}\\n\\nmodel = CatBoostClassifier(\\n    **params,\\n)\\n\\nmodel.fit(\\n    train[FEATS],\\n    y_train,\\n    eval_set=[(train[FEATS], y_train), (valid[FEATS], y_valid)],\\n    # cat_features=cat_cols,\\n    plot=True,\\n    # logging_level=\\\"Verbose\\\",  # you can uncomment this for text output\\n)\\n\\npreds = model.predict_proba(valid[FEATS])[:, 1]\\nacc = accuracy_score(y_valid, np.where(preds >= 0.5, 1, 0))\\nauc = roc_auc_score(y_valid, preds)\\n\\nprint(f\\\"VALID AUC : {auc} ACC : {acc}\\\\n\\\")\";\n                var nbb_formatted_code = \"params = {\\n    \\\"iterations\\\": 1000,\\n    \\\"learning_rate\\\": 0.06,  # 0.1\\n    \\\"eval_metric\\\": \\\"AUC\\\",\\n    \\\"random_seed\\\": 42,\\n    \\\"logging_level\\\": \\\"Silent\\\",\\n    \\\"early_stopping_rounds\\\": 50,\\n    \\\"use_best_model\\\": True,\\n    # \\\"task_type\\\": \\\"GPU\\\",\\n    \\\"bagging_temperature\\\": 1,\\n    \\\"cat_features\\\": cat_cols,\\n}\\n\\nmodel = CatBoostClassifier(\\n    **params,\\n)\\n\\nmodel.fit(\\n    train[FEATS],\\n    y_train,\\n    eval_set=[(train[FEATS], y_train), (valid[FEATS], y_valid)],\\n    # cat_features=cat_cols,\\n    plot=True,\\n    # logging_level=\\\"Verbose\\\",  # you can uncomment this for text output\\n)\\n\\npreds = model.predict_proba(valid[FEATS])[:, 1]\\nacc = accuracy_score(y_valid, np.where(preds >= 0.5, 1, 0))\\nauc = roc_auc_score(y_valid, preds)\\n\\nprint(f\\\"VALID AUC : {auc} ACC : {acc}\\\\n\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {\n",
    "    \"iterations\": 1000,\n",
    "    \"learning_rate\": 0.06,  # 0.1\n",
    "    \"eval_metric\": \"AUC\",\n",
    "    \"random_seed\": 42,\n",
    "    \"logging_level\": \"Silent\",\n",
    "    \"early_stopping_rounds\": 50,\n",
    "    \"use_best_model\": True,\n",
    "    # \"task_type\": \"GPU\",\n",
    "    \"bagging_temperature\": 1,\n",
    "    \"cat_features\": cat_cols,\n",
    "}\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    **params,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train[FEATS],\n",
    "    y_train,\n",
    "    eval_set=[(train[FEATS], y_train), (valid[FEATS], y_valid)],\n",
    "    # cat_features=cat_cols,\n",
    "    plot=True,\n",
    "    # logging_level=\"Verbose\",  # you can uncomment this for text output\n",
    ")\n",
    "\n",
    "preds = model.predict_proba(valid[FEATS])[:, 1]\n",
    "acc = accuracy_score(y_valid, np.where(preds >= 0.5, 1, 0))\n",
    "auc = roc_auc_score(y_valid, preds)\n",
    "\n",
    "print(f\"VALID AUC : {auc} ACC : {acc}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation Importance 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 33;\n                var nbb_unformatted_code = \"# perm = PermutationImportance(\\n#     model,\\n#     scoring=\\\"roc_auc\\\",\\n#     n_iter=1,\\n#     random_state=42,\\n#     cv=None,\\n#     refit=False,\\n# ).fit(valid[FEATS], y_valid)\\n# eli5.show_weights(perm, top=len(FEATS), feature_names=FEATS)\";\n                var nbb_formatted_code = \"# perm = PermutationImportance(\\n#     model,\\n#     scoring=\\\"roc_auc\\\",\\n#     n_iter=1,\\n#     random_state=42,\\n#     cv=None,\\n#     refit=False,\\n# ).fit(valid[FEATS], y_valid)\\n# eli5.show_weights(perm, top=len(FEATS), feature_names=FEATS)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perm = PermutationImportance(\n",
    "    model,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_iter=1,\n",
    "    random_state=42,\n",
    "    cv=None,\n",
    "    refit=False,\n",
    ").fit(valid[FEATS], y_valid)\n",
    "eli5.show_weights(perm, top=len(FEATS), feature_names=FEATS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>year</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>seenCount</td>\n",
       "      <td>0.133828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>wday</td>\n",
       "      <td>0.216741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KnowledgeTag</td>\n",
       "      <td>0.438534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tagCount</td>\n",
       "      <td>0.494794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>month</td>\n",
       "      <td>0.611772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hour</td>\n",
       "      <td>0.676635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cumCorrect</td>\n",
       "      <td>0.756245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>weekNum</td>\n",
       "      <td>0.849879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>userLVbyTestAVG</td>\n",
       "      <td>0.885907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tagCluster</td>\n",
       "      <td>0.977998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cumAccuracy</td>\n",
       "      <td>1.114077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bigClassElaspedTimeAvg</td>\n",
       "      <td>1.291313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bigClassCount</td>\n",
       "      <td>1.355239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>day</td>\n",
       "      <td>1.481629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>userLVbyTagAVG</td>\n",
       "      <td>2.254707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>testId</td>\n",
       "      <td>4.825644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>elapsedTime</td>\n",
       "      <td>6.560557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>elapsedTimeClass</td>\n",
       "      <td>6.566226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bigClass</td>\n",
       "      <td>8.192475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bigClassAccCate</td>\n",
       "      <td>10.951353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bigClassAcc</td>\n",
       "      <td>11.974673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assessmentItemID</td>\n",
       "      <td>15.604474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>elo</td>\n",
       "      <td>21.785301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  importance\n",
       "10                    year    0.000000\n",
       "16               seenCount    0.133828\n",
       "11                    wday    0.216741\n",
       "2             KnowledgeTag    0.438534\n",
       "18                tagCount    0.494794\n",
       "9                    month    0.611772\n",
       "13                    hour    0.676635\n",
       "7               cumCorrect    0.756245\n",
       "12                 weekNum    0.849879\n",
       "19         userLVbyTestAVG    0.885907\n",
       "17              tagCluster    0.977998\n",
       "6              cumAccuracy    1.114077\n",
       "22  bigClassElaspedTimeAvg    1.291313\n",
       "21           bigClassCount    1.355239\n",
       "8                      day    1.481629\n",
       "20          userLVbyTagAVG    2.254707\n",
       "1                   testId    4.825644\n",
       "14             elapsedTime    6.560557\n",
       "15        elapsedTimeClass    6.566226\n",
       "3                 bigClass    8.192475\n",
       "5          bigClassAccCate   10.951353\n",
       "4              bigClassAcc   11.974673\n",
       "0         assessmentItemID   15.604474\n",
       "23                     elo   21.785301"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 35;\n                var nbb_unformatted_code = \"feature_importances = pd.DataFrame(columns=[\\\"feature\\\", \\\"importance\\\"])\\nfeature_importances[\\\"feature\\\"] = train[FEATS].columns\\nfeature_importances[\\\"importance\\\"] = model.get_feature_importance(train_pool)\\nfeature_importances.sort_values(by=[\\\"importance\\\"], inplace=True)\\nfeature_importances\";\n                var nbb_formatted_code = \"feature_importances = pd.DataFrame(columns=[\\\"feature\\\", \\\"importance\\\"])\\nfeature_importances[\\\"feature\\\"] = train[FEATS].columns\\nfeature_importances[\\\"importance\\\"] = model.get_feature_importance(train_pool)\\nfeature_importances.sort_values(by=[\\\"importance\\\"], inplace=True)\\nfeature_importances\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(columns=[\"feature\", \"importance\"])\n",
    "feature_importances[\"feature\"] = train[FEATS].columns\n",
    "feature_importances[\"importance\"] = model.get_feature_importance(train_pool)\n",
    "feature_importances.sort_values(by=[\"importance\"], inplace=True)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-1. Inferece by test [-2] (test dataset 뒤에서 두번째 값으로 성능 측정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID AUC : 0.8232006612876088 ACC : 0.7580645161290323\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 26;\n                var nbb_unformatted_code = \"# use test dataset only for valid\\ntest = df[(df.dataset == 2) & (df.answerCode != -1)]  # -1 \\uc778 answerCode \\uc81c\\uc678\\n\\n# test\\ub370\\uc774\\ud130\\uc14b\\uc740 \\uac01 \\uc720\\uc800\\uc758 \\ub9c8\\uc9c0\\ub9c9 interaction\\ub9cc \\ucd94\\ucd9c\\ntest = test[test[\\\"userID\\\"] != test[\\\"userID\\\"].shift(-1)]\\ntest = feature_engineering(test, option=\\\"total\\\")\\n\\ny_test = test[\\\"answerCode\\\"]\\ntest = test.drop([\\\"answerCode\\\"], axis=1)\\n\\npreds = model.predict_proba(test[FEATS])[:, 1]\\nacc = accuracy_score(y_test, np.where(preds >= 0.5, 1, 0))\\nauc = roc_auc_score(y_test, preds)\\n\\nprint(f\\\"VALID AUC : {auc} ACC : {acc}\\\")\";\n                var nbb_formatted_code = \"# use test dataset only for valid\\ntest = df[(df.dataset == 2) & (df.answerCode != -1)]  # -1 \\uc778 answerCode \\uc81c\\uc678\\n\\n# test\\ub370\\uc774\\ud130\\uc14b\\uc740 \\uac01 \\uc720\\uc800\\uc758 \\ub9c8\\uc9c0\\ub9c9 interaction\\ub9cc \\ucd94\\ucd9c\\ntest = test[test[\\\"userID\\\"] != test[\\\"userID\\\"].shift(-1)]\\ntest = feature_engineering(test, option=\\\"total\\\")\\n\\ny_test = test[\\\"answerCode\\\"]\\ntest = test.drop([\\\"answerCode\\\"], axis=1)\\n\\npreds = model.predict_proba(test[FEATS])[:, 1]\\nacc = accuracy_score(y_test, np.where(preds >= 0.5, 1, 0))\\nauc = roc_auc_score(y_test, preds)\\n\\nprint(f\\\"VALID AUC : {auc} ACC : {acc}\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use test dataset only for valid\n",
    "test = df[(df.dataset == 2) & (df.answerCode != -1)]  # -1 인 answerCode 제외\n",
    "\n",
    "# test데이터셋은 각 유저의 마지막 interaction만 추출\n",
    "test = test[test[\"userID\"] != test[\"userID\"].shift(-1)]\n",
    "test = feature_engineering(test, option=\"total\")\n",
    "\n",
    "y_test = test[\"answerCode\"]\n",
    "test = test.drop([\"answerCode\"], axis=1)\n",
    "\n",
    "preds = model.predict_proba(test[FEATS])[:, 1]\n",
    "acc = accuracy_score(y_test, np.where(preds >= 0.5, 1, 0))\n",
    "auc = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(f\"VALID AUC : {auc} ACC : {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-2. 종테기 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 46;\n                var nbb_unformatted_code = \"ground_truth = pd.read_csv(\\\"/opt/ml/workspace/submission_tester/ground_truth.csv\\\")\";\n                var nbb_formatted_code = \"ground_truth = pd.read_csv(\\\"/opt/ml/workspace/submission_tester/ground_truth.csv\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ground_truth = pd.read_csv(\"/opt/ml/workspace/submission_tester/ground_truth.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 47;\n                var nbb_unformatted_code = \"test_df = df[df.dataset == 2]\\n\\n# LEAVE LAST INTERACTION ONLY\\ntest_df = test_df[test_df[\\\"userID\\\"] != test_df[\\\"userID\\\"].shift(-1)]\\ntest_df = feature_engineering(test_df, option=\\\"total\\\")\\n\\n# DROP ANSWERCODE\\ntest_df = test_df.drop([\\\"answerCode\\\"], axis=1)\";\n                var nbb_formatted_code = \"test_df = df[df.dataset == 2]\\n\\n# LEAVE LAST INTERACTION ONLY\\ntest_df = test_df[test_df[\\\"userID\\\"] != test_df[\\\"userID\\\"].shift(-1)]\\ntest_df = feature_engineering(test_df, option=\\\"total\\\")\\n\\n# DROP ANSWERCODE\\ntest_df = test_df.drop([\\\"answerCode\\\"], axis=1)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = df[df.dataset == 2]\n",
    "\n",
    "# LEAVE LAST INTERACTION ONLY\n",
    "test_df = test_df[test_df[\"userID\"] != test_df[\"userID\"].shift(-1)]\n",
    "test_df = feature_engineering(test_df, option=\"total\")\n",
    "\n",
    "# DROP ANSWERCODE\n",
    "test_df = test_df.drop([\"answerCode\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 48;\n                var nbb_unformatted_code = \"# MAKE PREDICTION\\ntotal_preds = model.predict_proba(test_df[FEATS])[:, 1]\";\n                var nbb_formatted_code = \"# MAKE PREDICTION\\ntotal_preds = model.predict_proba(test_df[FEATS])[:, 1]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MAKE PREDICTION\n",
    "total_preds = model.predict_proba(test_df[FEATS])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Contains hidden testcase *\n",
      "auc : 0.7974905860840279\n",
      "acc : 0.7204301075268817\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 49;\n                var nbb_unformatted_code = \"auc = roc_auc_score(ground_truth[\\\"gt\\\"], total_preds)\\nacc = accuracy_score(ground_truth[\\\"gt\\\"], np.where(total_preds >= 0.5, 1, 0))\\n\\nprint(\\\"* Contains hidden testcase *\\\")\\nprint(f\\\"auc : {auc}\\\\nacc : {acc}\\\")\";\n                var nbb_formatted_code = \"auc = roc_auc_score(ground_truth[\\\"gt\\\"], total_preds)\\nacc = accuracy_score(ground_truth[\\\"gt\\\"], np.where(total_preds >= 0.5, 1, 0))\\n\\nprint(\\\"* Contains hidden testcase *\\\")\\nprint(f\\\"auc : {auc}\\\\nacc : {acc}\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc = roc_auc_score(ground_truth[\"gt\"], total_preds)\n",
    "acc = accuracy_score(ground_truth[\"gt\"], np.where(total_preds >= 0.5, 1, 0))\n",
    "\n",
    "print(\"* Contains hidden testcase *\")\n",
    "print(f\"auc : {auc}\\nacc : {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-3. 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing prediction : output/submission.csv\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 40;\n                var nbb_unformatted_code = \"# SAVE OUTPUT\\noutput_dir = \\\"output/\\\"\\nwrite_path = os.path.join(output_dir, \\\"submission.csv\\\")\\nif not os.path.exists(output_dir):\\n    os.makedirs(output_dir)\\nwith open(write_path, \\\"w\\\", encoding=\\\"utf8\\\") as w:\\n    print(\\\"writing prediction : {}\\\".format(write_path))\\n    w.write(\\\"id,prediction\\\\n\\\")\\n    for id, p in enumerate(total_preds):\\n        w.write(\\\"{},{}\\\\n\\\".format(id, p))\";\n                var nbb_formatted_code = \"# SAVE OUTPUT\\noutput_dir = \\\"output/\\\"\\nwrite_path = os.path.join(output_dir, \\\"submission.csv\\\")\\nif not os.path.exists(output_dir):\\n    os.makedirs(output_dir)\\nwith open(write_path, \\\"w\\\", encoding=\\\"utf8\\\") as w:\\n    print(\\\"writing prediction : {}\\\".format(write_path))\\n    w.write(\\\"id,prediction\\\\n\\\")\\n    for id, p in enumerate(total_preds):\\n        w.write(\\\"{},{}\\\\n\\\".format(id, p))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SAVE OUTPUT\n",
    "output_dir = \"output/\"\n",
    "write_path = os.path.join(output_dir, \"submission.csv\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "with open(write_path, \"w\", encoding=\"utf8\") as w:\n",
    "    print(\"writing prediction : {}\".format(write_path))\n",
    "    w.write(\"id,prediction\\n\")\n",
    "    for id, p in enumerate(total_preds):\n",
    "        w.write(\"{},{}\\n\".format(id, p))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 📌 LGBM: Light Gradient Boosting Model (ver. 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-05-24T09:49:29.375544Z","start_time":"2021-05-24T09:49:28.999092Z"},"id":"Uq_TJqbdhfQu"},"outputs":[],"source":["# python black formatting\n","%load_ext nb_black\n","%load_ext lab_black\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import lightgbm as lgb\n","\n","import os\n","import random\n","import eli5\n","import warnings\n","\n","from sklearn import preprocessing\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import accuracy_score\n","from eli5.sklearn import PermutationImportance\n","\n","warnings.filterwarnings(action=\"ignore\")  # 경고 출력 무시"]},{"cell_type":"markdown","metadata":{"id":"QZlm5HSmhfQv"},"source":["## ✅ 데이터 로딩"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-05-24T09:49:29.678737Z","start_time":"2021-05-24T09:49:29.376581Z"},"id":"s6qgJ8MLhfQw"},"outputs":[],"source":["DATA_PATH = \"/opt/ml/input/data/all_feature_data.csv\"\n","GT_DATA_PATH = \"/opt/ml/input/data/ground_truth.csv\"\n","\n","# train data 불러오기\n","df = pd.read_csv(DATA_PATH, parse_dates=[\"Timestamp\"])\n","df = df.sort_values(by=[\"userID\", \"Timestamp\"]).reset_index(drop=True)\n","\n","# ground truth 불러오기\n","gt = pd.read_csv(GT_DATA_PATH)[\"gt\"]"]},{"cell_type":"markdown","metadata":{},"source":["## ✅ Feature Engineering\n","- Special mission의 Feature Engineering 코드\n","- Category feature의 변환"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 카테고리형 변수 설정하는 함수\n","def feature_engineering(df):\n","\n","    # 카테고리형 feature\n","    categories = [\n","        \"assessmentItemID\",\n","        \"testId\",\n","    ]\n","\n","    # label encode your categorical columns\n","    le = preprocessing.LabelEncoder()\n","    for category in categories:\n","        df[category] = le.fit_transform(df[category])\n","\n","    return df\n","\n","\n","df = feature_engineering(df)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# train과 test 데이터 나누기\n","train_df = df[df.dataset == 1]\n","test_df = df[df.dataset == 2]"]},{"cell_type":"markdown","metadata":{"id":"5VZzei3DhfQy"},"source":["## ✅ Train/Test 데이터 셋 분리 (option1, option2에서 하나만 실행)"]},{"cell_type":"markdown","metadata":{},"source":["### 📍 Option 1\n","- train 데이터에서 train, valid set을 나눔"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-05-24T09:49:29.684739Z","start_time":"2021-05-24T09:49:28.982Z"},"id":"YOPWK7ckhfQz"},"outputs":[],"source":["# train과 valid 데이터셋은 사용자 별로 묶어서 분리를 해주어야함\n","random.seed(42)\n","\n","# 데이터에 포함된 answerCode 비율을 동일하게 맞추어준다.\n","def make_proportion_equal(df: pd.DataFrame):\n","\n","    # index를 다시 새롭게 0부터 매긴다. (학습 지장 X)\n","    df = df.reset_index(drop=True)\n","\n","    # answerCode가 1 이면 hit, 0이면 error 라고 표현\n","    error_index = list(df[df.answerCode == 0].index)\n","    hit_index = list(df[df.answerCode == 1].index)\n","\n","    # 0의 개수와 1의 개수를 계산\n","    error_len = len(error_index)\n","    hit_len = len(hit_index)\n","\n","    # 더 많은 것은 낮은 것을 기준으로 맞추어준다.\n","    threshold = min(error_len, hit_len)\n","\n","    if error_len > threshold:\n","        random.shuffle(error_index)\n","        error_index = error_index[:threshold]\n","\n","    elif hit_len > threshold:\n","        random.shuffle(hit_index)\n","        hit_index = hit_index[:threshold]\n","\n","    # 최종적으로 사용할 데이터 index 들\n","    error_index.extend(hit_index)\n","\n","    return df.iloc[error_index]\n","\n","\n","def option1_train_test_split(df, ratio=0.9, split=True):\n","\n","    # users = [userID, user의 interaction 수]\n","    users = list(zip(df[\"userID\"].value_counts().index, df[\"userID\"].value_counts()))\n","    random.shuffle(users)\n","\n","    # 전체 interaction의 ratio만큼 train_dataset으로 사용\n","    # 유저가 train, valid로 분리되어서는 안되기 때문에 묶어서 연산을 진행\n","    max_train_data_len = ratio * len(df)\n","    sum_of_train_data = 0\n","    train_users = []\n","\n","    # train_data 에 포함될 user 추출\n","    for user_id, count in users:\n","        sum_of_train_data += count\n","        if max_train_data_len < sum_of_train_data:\n","            break\n","        train_users.append(user_id)\n","\n","    # train dataset, valid dataset 생성\n","    train = df[df[\"userID\"].isin(train_users)]\n","    valid = df[df[\"userID\"].isin(train_users) == False]\n","\n","    # test데이터셋은 각 유저의 마지막 interaction만 추출\n","    valid = valid[valid[\"userID\"] != valid[\"userID\"].shift(-1)]\n","\n","    # 🎯 만약 비율을 같게 만들고 싶다면 사용 (데이터 감소되는 단점)\n","    train = make_proportion_equal(train)\n","\n","    return train, valid\n","\n","\n","# 유저 별 분리\n","train, valid = option1_train_test_split(train_df)"]},{"cell_type":"markdown","metadata":{},"source":["### 📍 Option 2\n","- train 데이터를 모두 훈련에 사용\n","- valid를 test셋의 마지막 두번째 데이터로 진행"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def option2_train_test_split(df):\n","    # use train dataset only for train\n","    train = df[df.dataset == 1]\n","\n","    # use test dataset only for valid\n","    test = df[(df.dataset == 2) & (df.answerCode != -1)]  # -1 인 answerCode 제외\n","\n","    # test데이터셋은 각 유저의 마지막 interaction만 추출\n","    test = test[test[\"userID\"] != test[\"userID\"].shift(-1)]\n","\n","    return train, test\n","\n","\n","train, valid = option2_train_test_split(df)"]},{"cell_type":"markdown","metadata":{},"source":["## ✅ 데이터셋 정의"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 학습에 사용하는 feature와 최종으로 맞추어야 하는 값 설정\n","y_train = train[\"answerCode\"]\n","train = train.drop([\"answerCode\"], axis=1)\n","\n","y_valid = valid[\"answerCode\"]\n","valid = valid.drop([\"answerCode\"], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# dataset에 포함된 feature 목록\n","sorted(list(train.columns))"]},{"cell_type":"markdown","metadata":{},"source":["- FEATS 에 사용할 feature를 설정"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-05-24T09:49:29.686739Z","start_time":"2021-05-24T09:49:28.984Z"},"id":"i3HzdoybhfQ0"},"outputs":[],"source":["FEATS = [\n","    # \"KTAccuracyCate\",\n","    \"KnowledgeTag\",\n","    # \"KnowledgeTagAcc\",\n","    # \"Timestamp\",\n","    \"accuracy\",\n","    \"assessmentItemID\",\n","    \"bigClass\",\n","    \"bigClassAcc\",\n","    \"bigClassAccCate\",\n","    \"bigClassElaspedTimeAvg\",\n","    \"cumAccuracy\",\n","    \"cumCorrect\",\n","    \"dataset\",\n","    \"day\",\n","    # \"elapsedTime\",\n","    \"elapsedTimeClass\",\n","    \"elapsedTime_ver2\",\n","    \"elo\",\n","    \"hour\",\n","    \"month\",\n","    \"problemNumber\",\n","    \"recAccuracy\",\n","    # \"recCount\",\n","    \"seenCount\",\n","    \"tagCluster\",\n","    \"tagCount\",\n","    # \"tagLV\",\n","    # \"testId\",\n","    # \"testLV\",\n","    \"userID\",\n","    # \"userLVbyTag\",\n","    \"userLVbyTagAVG\",\n","    # \"userLVbyTest\",\n","    \"userLVbyTestAVG\",\n","    \"wday\",\n","    \"weekNum\",\n","    \"year\",\n","    \"z-time\",\n","]"]},{"cell_type":"markdown","metadata":{"id":"KiHss_BBhfQ2"},"source":["## ✅ 훈련 및 검증 (permutation Importance 사용)"]},{"cell_type":"markdown","metadata":{},"source":["### 🔍 hyper parameter 참고\n","- https://smecsm.tistory.com/133\n","- https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html"]},{"cell_type":"markdown","metadata":{},"source":["### 🔍 LGBM Parameter 설명\n","\n","[1] `max_depth` : tree의 최대 깊이 (과적합된 것 같으면 줄이기)  \n","[2] `min_data_in_leaf` : leaf가 가진 최소 레코드 수 (default: 20, 최적) 과적합 해결할 때 사용  \n","[3] `feature_fraction` : Random Forest 에서만 사용. : feature에서 주어진 비율만큼만 랜덤으로 사용  \n","[4] `bagging_fraction` : 매 iteration마다 모든 데이터를 사용하지 않고 주어진 비율 만큼 사용 (과적합 방지에 사용)  \n","[5] `early_stopping_round` : early stopping parameter  \n","[6] `reg_lambda` : regularization (정규화, 0~1 값)  \n","[7] `min_gain_to_split` : 트리를 분기하기 위해 필요한 최소한의 gain 값  \n","[8] `max_cat_group` : 카테고리 수가 클때, 과적합을 방지하는 분기 포인트를 찾는다. (default: 64)  \n","[9] `Task` : 데이터에 대해서 수행하고자 하는 임무 구체화 (train or predict)  \n","[10] `objective` : 어떤 문제를 해결하는지 결정 (regression, binary, multiclass)  \n","[11] `boosting` : (gbdt, rf, dart, goss)  \n","[12] `n_estimators` : iteration(epoch) 수  \n","[13] `learning rate` : 학습률  \n","[14] `num_leaves` : 전체 tree의 leave수 (default: 31)  \n","[15] `metric` : loss function (auc, binary_logloss, ...)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# TODO : tunning\n","params = {\n","    \"max_depth\": 8,  # 8,\n","    \"min_data_in_leaf\": 1000,\n","    # \"feature_fraction\": 0.6,  # 0.8,\n","    \"bagging_fraction\": 0.75,\n","    # \"max_cat_group\": 64,\n","    \"objective\": \"binary\",\n","    \"boosting\": \"gbdt\",  # dart\n","    \"learning_rate\": 0.01,  # 0.01,\n","    # \"bagging_freq\": 5,\n","    \"seed\": 42,\n","    # \"max_bin\": 50,\n","    \"num_leaves\": 80,  # 40,\n","    \"metric\": \"auc\",\n","}\n","\n","model = lgb.LGBMClassifier(\n","    **params,\n","    n_estimators=1000,\n","    silent=-1,\n",")\n","\n","model.fit(\n","    X=train[FEATS],\n","    y=y_train,\n","    early_stopping_rounds=100,\n","    eval_set=[(train[FEATS], y_train), (valid[FEATS], y_valid)],\n","    eval_names=[\"train\", \"valid\"],\n","    eval_metric=\"roc_auc\",\n","    verbose=100,\n",")\n","\n","\n","preds = model.predict_proba(valid[FEATS])[:, 1]\n","acc = accuracy_score(y_valid, np.where(preds >= 0.5, 1, 0))\n","auc = roc_auc_score(y_valid, preds)\n","\n","print(f\"VALID AUC : {auc} ACC : {acc}\\n\")\n","\n","perm = PermutationImportance(\n","    model, scoring=\"roc_auc\", n_iter=1, random_state=42, cv=None, refit=False\n",").fit(valid[FEATS], y_valid)\n","eli5.show_weights(perm, top=len(FEATS), feature_names=FEATS)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# INSTALL MATPLOTLIB IN ADVANCE\n","ax = lgb.plot_importance(model, dpi=150, figsize=(15, 7))\n","ax.spines[\"top\"].set_visible(False)\n","ax.spines[\"right\"].set_visible(False)\n","ax.spines[\"left\"].set_linewidth(1.5)\n","ax.spines[\"bottom\"].set_linewidth(1.5)"]},{"cell_type":"markdown","metadata":{},"source":["### 🔍 Permutation Importance 시각화"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["perm_imp_df = pd.DataFrame()\n","perm_imp_df[\"feature\"] = FEATS\n","perm_imp_df[\"importance\"] = perm.feature_importances_\n","perm_imp_df[\"std\"] = perm.feature_importances_std_\n","perm_imp_df.sort_values(by=\"importance\", ascending=False, inplace=True)\n","perm_imp_df.reset_index(drop=True, inplace=True)\n","perm_imp_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.rcParams[\"figure.dpi\"] = 150  # 고해상도 설정\n","\n","permutaion_importace = plt.figure(figsize=(15, 7))\n","ax = permutaion_importace.add_subplot()\n","\n","ax.set_xlim(\n","    min(perm_imp_df[\"importance\"]) - 0.003, max(perm_imp_df[\"importance\"]) + 0.01\n",")\n","ax.spines[\"top\"].set_visible(False)\n","ax.spines[\"right\"].set_visible(False)\n","ax.spines[\"left\"].set_linewidth(1.5)\n","ax.spines[\"bottom\"].set_linewidth(1.5)\n","\n","sns.barplot(x=\"importance\", y=\"feature\", data=perm_imp_df, palette=\"pastel\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### 🔍 Inferece by test [-2] \n","\n","> (test dataset 뒤에서 두번째 값으로 성능 측정)  \n","> option1으로 데이터를 분할했을 때만 유의미함!"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# use test dataset only for valid\n","test = df[(df.dataset == 2) & (df.answerCode != -1)]  # -1 인 answerCode 제외\n","\n","# test데이터셋은 각 유저의 마지막 interaction만 추출\n","test = test[test[\"userID\"] != test[\"userID\"].shift(-1)]\n","\n","y_test = test[\"answerCode\"]\n","test = test.drop([\"answerCode\"], axis=1)\n","\n","preds = model.predict_proba(test[FEATS])[:, 1]\n","acc = accuracy_score(y_test, np.where(preds >= 0.5, 1, 0))\n","auc = roc_auc_score(y_test, preds)\n","\n","print(f\"VALID AUC : {auc} ACC : {acc}\\n\")"]},{"cell_type":"markdown","metadata":{"id":"8Bsff1ZVhfQ3"},"source":["## ✅ Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-05-24T09:49:29.691738Z","start_time":"2021-05-24T09:49:28.992Z"},"id":"N6YEFm8IhfQ3"},"outputs":[],"source":["test_df = df[df.dataset == 2]\n","\n","# LEAVE LAST INTERACTION ONLY\n","test_df = test_df[test_df[\"userID\"] != test_df[\"userID\"].shift(-1)]\n","\n","# DROP ANSWERCODE\n","test_df = test_df.drop([\"answerCode\"], axis=1)\n","\n","# MAKE PREDICTION\n","total_preds = model.predict_proba(test_df[FEATS])[:, 1]"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-05-24T09:49:29.694736Z","start_time":"2021-05-24T09:49:28.995Z"},"id":"f8PvohzwhfQ4"},"outputs":[],"source":["# SAVE OUTPUT\n","output_dir = \"output/\"\n","write_path = os.path.join(output_dir, \"submission.csv\")\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","with open(write_path, \"w\", encoding=\"utf8\") as w:\n","    print(\"writing prediction : {}\".format(write_path))\n","    w.write(\"id,prediction\\n\")\n","    for id, p in enumerate(total_preds):\n","        w.write(\"{},{}\\n\".format(id, p))"]},{"cell_type":"markdown","metadata":{},"source":["## ✅ Real Submission Score"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pred = pd.read_csv(\"./output/submission.csv\")[\"prediction\"]\n","answer = gt\n","\n","acc = accuracy_score(answer, np.where(pred >= 0.5, 1, 0))\n","auc = roc_auc_score(answer, pred)\n","\n","print(f\"VALID AUC : {auc} ACC : {acc}\\n\")"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"(미션-2) LGBM Baseline.ipynb의 사본","provenance":[{"file_id":"1P8UcsK9m3EVF48Pa45kvHPQRwudqU8PT","timestamp":1650348237411}]},"interpreter":{"hash":"d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"},"kernelspec":{"display_name":"Python 3.8.5 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":0}
